import os
import time
import requests
import asyncio
from datetime import datetime, time as dt_time, timedelta
from bs4 import BeautifulSoup
from transformers import pipeline
from huggingface_hub import login
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, CallbackContext
import matplotlib.pyplot as plt
import re
from urllib.parse import urljoin
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor, as_completed  # Th√™m as_completed v√†o ƒë√¢y

# ƒêƒÉng nh·∫≠p Hugging Face ƒë·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh t√≥m t·∫Øt
login("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")

# T·∫£i m√¥ h√¨nh t√≥m t·∫Øt
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

# C·∫•u h√¨nh Telegram Bot
TELEGRAM_BOT_TOKEN = "7053413496:AAFuwt1b8ff2FKxKyTYaUv91IemHqLMTc0g"
CHAT_ID = "6632338735"

# √Ånh x·∫° t√™n ch·ªâ s·ªë/h√†ng h√≥a sang ti·∫øng Vi·ªát
major_translation = {
    "Crude Oil": "D·∫ßu th√¥", "Brent": "D·∫ßu Brent", "Natural gas": "Kh√≠ t·ª± nhi√™n",
    "Gasoline": "XƒÉng", "Coal": "Than ƒë√°", "TTF Gas": "Kh√≠ TTF", "Uranium": "Urani",
    "Urals Oil": "D·∫ßu Urals", "Copper": "ƒê·ªìng", "Gold": "V√†ng", "HRC Steel": "Th√©p HRC",
    "Iron Ore": "Qu·∫∑ng s·∫Øt", "Silver": "B·∫°c", "Steel": "Th√©p", "Wheat": "L√∫a m√¨",
    "Rubber": "Cao su", "Coffee": "C√† ph√™", "Rice": "G·∫°o", "Sugar": "ƒê∆∞·ªùng", "Urea": "Ph√¢n ure"
}

# H√†m t·∫£i d·ªØ li·ªáu t·ª´ web
def fetch_web_data(url):
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        return response.content
    except requests.exceptions.RequestException as e:
        print(f"L·ªói khi t·∫£i d·ªØ li·ªáu t·ª´ {url}: {e}")
        return None

# H√†m l√†m s·∫°ch t√™n ch·ªâ s·ªë/h√†ng h√≥a
def clean_major_name(major):
    return major.split("\n\n")[0].strip() if "\n\n" in major else major.strip()

# H√†m tr√≠ch xu·∫•t v√† l·ªçc d·ªØ li·ªáu t·ª´ b·∫£ng HTML
def extract_and_filter_data(table, selected_indices, column_indices):
    rows = table.find_all('tr')[1:]
    filtered_data = []
    for row in rows:
        cols = [col.text.strip() for col in row.find_all(['td', 'th'])]
        if not cols or len(cols) < max(column_indices) + 1:
            continue
        major = clean_major_name(cols[column_indices[0]])
        if major in selected_indices:
            translated_major = major_translation.get(major, major)
            filtered_row = [translated_major, cols[column_indices[1]], cols[column_indices[2]]]
            if len(column_indices) > 3:
                filtered_row.append(cols[column_indices[3]])
            filtered_data.append(filtered_row)
    return filtered_data

# H√†m ƒë·ªãnh d·∫°ng gi√° tr·ªã s·ªë
def format_value(value):
    try:
        if "." in value:
            integer_part, decimal_part = value.split(".", 1)
            return f"{integer_part}.{decimal_part.zfill(2)}"
        return f"{value}.00"
    except (ValueError, AttributeError):
        return value

# H√†m th√™m emoji d·ª±a tr√™n ph·∫ßn trƒÉm thay ƒë·ªïi
def get_emoji(value):
    try:
        numeric_value = float(value.strip('%'))
        return "üü¢" if numeric_value > 0 else "üî¥" if numeric_value < 0 else "üü°"
    except (ValueError, AttributeError):
        return "  "

# H√†m v·∫Ω bi·ªÉu ƒë·ªì thay ƒë·ªïi h√†ng tu·∫ßn
def plot_weekly_change(data, title):
    majors = [row[0] for row in data]
    weekly_changes = [float(row[3].strip('%') if row[3] else "0") if len(row) > 3 else 0 for row in data]
    plt.figure(figsize=(12, 6))
    bars = plt.barh(majors, weekly_changes, color=['green' if p > 0 else 'red' for p in weekly_changes])
    plt.axvline(0, color='black', linestyle='--', linewidth=0.8)
    plt.title(title, fontsize=16)
    plt.xlabel("Ph·∫ßn trƒÉm thay ƒë·ªïi (%)", fontsize=12)
    plt.ylabel("Ch·ªâ s·ªë/H√†ng h√≥a", fontsize=12)
    plt.grid(axis='x', linestyle='--', alpha=0.7)
    for bar in bars:
        plt.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,
                 f'{bar.get_width():.1f}%', va='center', ha='left')
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    chart_file = f"chart_{timestamp}.png"
    plt.tight_layout()
    plt.savefig(chart_file)
    plt.close()
    return chart_file

# H√†m t·∫°o b·∫£ng HTML
def create_html_table(data, title):
    titles = ["üíª", "Major", "Price", "%"]
    max_major_width = max(len(row[0]) for row in data) if data else len(titles[1])
    max_price_width = max(len(format_value(row[1])) for row in data) if data else len(titles[2])
    max_percentage_width = max(len(row[2]) for row in data) if data else len(titles[3])
    html_table = f"<b>{title}</b>\n\n<pre><code>\n"
    html_table += f"| {titles[0]:^2} | {titles[1]:^{max_major_width}} | {titles[2]:^{max_price_width}} | {titles[3]:^{max_percentage_width}} |\n"
    for row in data:
        emoji = get_emoji(row[2]) if len(row) > 2 else "  "
        html_table += f"| {emoji:^2} | {row[0]:<{max_major_width}} | {format_value(row[1]):>{max_price_width}} | {row[2]:>{max_percentage_width}} |\n"
    html_table += "</code></pre>"
    return html_table

# H√†m l·∫•y d·ªØ li·ªáu c·ªï phi·∫øu
def fetch_stocks_data():
    url = "https://tradingeconomics.com/stocks"
    content = fetch_web_data(url)
    if not content:
        return "Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu c·ªï phi·∫øu.", None
    soup = BeautifulSoup(content, 'html.parser')
    tables = soup.find_all('table')
    if len(tables) < 4:
        return "Kh√¥ng ƒë·ªß b·∫£ng d·ªØ li·ªáu c·ªï phi·∫øu.", None
    table_1 = tables[0]
    table_4 = tables[3]
    selected_indices_table_1 = ["US500", "US30", "US100", "JP225", "GB100", "DE40", "FR40"]
    selected_indices_table_4 = ["VN", "HNX"]
    filtered_table_1 = extract_and_filter_data(table_1, selected_indices_table_1, [1, 2, 4, 5])
    filtered_table_4 = extract_and_filter_data(table_4, selected_indices_table_4, [1, 2, 4, 5])
    combined_data = filtered_table_1 + filtered_table_4
    html_table = create_html_table(combined_data, "Ch·ªâ s·ªë c·ªï phi·∫øu th·∫ø gi·ªõi")
    chart_file = plot_weekly_change(combined_data, "Bi·∫øn ƒë·ªông tu·∫ßn c·ªï phi·∫øu")
    return html_table, chart_file

# H√†m l·∫•y d·ªØ li·ªáu h√†ng h√≥a
def fetch_commodities_data():
    url = "https://tradingeconomics.com/commodities"
    content = fetch_web_data(url)
    if not content:
        return "Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu h√†ng h√≥a.", None
    soup = BeautifulSoup(content, 'html.parser')
    tables = soup.find_all('table')
    if len(tables) < 4:
        return "Kh√¥ng ƒë·ªß b·∫£ng d·ªØ li·ªáu h√†ng h√≥a.", None
    combined_data = []
    selected_indices = {
        "B·∫£ng 1": ["Crude Oil", "Brent", "Natural gas", "Gasoline", "Coal", "TTF Gas", "Uranium", "Urals Oil"],
        "B·∫£ng 2": ["Copper", "Gold", "HRC Steel", "Iron Ore", "Silver", "Steel"],
        "B·∫£ng 3": ["Wheat", "Rubber", "Coffee", "Rice", "Sugar"],
        "B·∫£ng 4": ["Urea"]
    }
    for i, table in enumerate(tables[:4]):
        selected = selected_indices[f"B·∫£ng {i+1}"]
        combined_data += extract_and_filter_data(table, selected, [0, 1, 3, 4])
    html_table = create_html_table(combined_data, "Gi√° c·∫£ h√†ng h√≥a")
    chart_file = plot_weekly_change(combined_data, "Bi·∫øn ƒë·ªông tu·∫ßn h√†ng h√≥a")
    return html_table, chart_file

# H√†m l·∫•y d·ªØ li·ªáu t√†i ch√≠nh
def fetch_financials_data():
    url = "https://tradingeconomics.com/currencies"
    content = fetch_web_data(url)
    if not content:
        return "Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu t√†i ch√≠nh.", None
    soup = BeautifulSoup(content, 'html.parser')
    tables = soup.find_all('table')
    if len(tables) < 4:
        return "Kh√¥ng ƒë·ªß b·∫£ng d·ªØ li·ªáu t√†i ch√≠nh.", None
    table_1 = tables[0]
    table_4 = tables[3]
    selected_indices_table_1 = ["DXY", "EURUSD", "USDJPY"]
    selected_indices_table_4 = ["USDVND"]
    filtered_table_1 = extract_and_filter_data(table_1, selected_indices_table_1, [1, 2, 4, 5])
    filtered_table_4 = extract_and_filter_data(table_4, selected_indices_table_4, [1, 2, 4, 5])
    combined_data = filtered_table_1 + filtered_table_4
    html_table = create_html_table(combined_data, "T·ª∑ gi√° ti·ªÅn t·ªá")
    chart_file = plot_weekly_change(combined_data, "Bi·∫øn ƒë·ªông tu·∫ßn t√†i ch√≠nh")
    return html_table, chart_file

# H√†m chuy·ªÉn ƒë·ªïi th·ªùi gian t∆∞∆°ng ƒë·ªëi th√†nh th·ªùi gian tuy·ªát ƒë·ªëi
def parse_relative_time(relative_time, reference_date=None):
    if reference_date is None:
        reference_date = datetime.now()
    try:
        if "just now" in relative_time.lower():
            return reference_date
        elif "minute" in relative_time.lower():
            minutes = int(re.search(r'\d+', relative_time).group())
            return reference_date - timedelta(minutes=minutes)
        elif "hour" in relative_time.lower():
            hours = int(re.search(r'\d+', relative_time).group())
            return reference_date - timedelta(hours=hours)
        elif "day" in relative_time.lower():
            days = int(re.search(r'\d+', relative_time).group())
            return reference_date - timedelta(days=days)
        elif "week" in relative_time.lower():
            weeks = int(re.search(r'\d+', relative_time).group())
            return reference_date - timedelta(weeks=weeks)
        elif "month" in relative_time.lower():
            months = int(re.search(r'\d+', relative_time).group())
            return reference_date - timedelta(days=months * 30)
        elif "year" in relative_time.lower():
            years = int(re.search(r'\d+', relative_time).group())
            return reference_date - timedelta(days=years * 365)
        else:
            print(f"Th·ªùi gian kh√¥ng h·ª£p l·ªá: {relative_time}")
            return None
    except Exception as e:
        print(f"L·ªói khi ph√¢n t√≠ch th·ªùi gian '{relative_time}': {e}")
        return None

# H√†m thu th·∫≠p b√†i vi·∫øt trong m·ªôt ng√†y c·ª• th·ªÉ
# H√†m thu th·∫≠p b√†i vi·∫øt trong m·ªôt ng√†y c·ª• th·ªÉ
def fetch_articles(max_articles=10, specific_date=None):
    if specific_date is None:
        specific_date = datetime.now()
    else:
        if isinstance(specific_date, str):
            specific_date = datetime.strptime(specific_date, "%d/%m/%Y")
    
    start_of_day = specific_date.replace(hour=0, minute=0, second=0, microsecond=0)
    end_of_day = start_of_day + timedelta(days=1) - timedelta(seconds=1)

    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-extensions")
    chrome_options.add_argument("start-maximized")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    )

    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
    except Exception as e:
        print(f"L·ªói khi kh·ªüi t·∫°o ChromeDriver: {e}")
        return []

    articles = []
    seen_titles = set()
    try:
        driver.get("https://tradingeconomics.com/stream")
        WebDriverWait(driver, 15).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, "li.list-group-item.te-stream-item"))
        )

        last_height = driver.execute_script("return document.body.scrollHeight")
        max_attempts = 25
        for attempt in range(max_attempts):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(4)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                print(f"Kh√¥ng c√≥ n·ªôi dung m·ªõi sau l·∫ßn cu·ªôn {attempt + 1}, d·ª´ng l·∫°i.")
                break
            last_height = new_height

            page_source = driver.page_source
            soup = BeautifulSoup(page_source, "html.parser")
            article_elements = soup.select("li.list-group-item.te-stream-item")

            print(f"S·ªë l∆∞·ª£ng b√†i vi·∫øt t√¨m th·∫•y sau cu·ªôn {attempt + 1}: {len(article_elements)}")

            for i, elem in enumerate(article_elements):
                time_elem = elem.find("small")
                if not time_elem:
                    print(f"B√†i {i}: Thi·∫øu th·ªùi gian (small)")
                    continue

                relative_time = time_elem.text.strip()
                if not relative_time:
                    print(f"B√†i {i}: Th·ªùi gian r·ªóng")
                    continue

                # T√¨m t·∫•t c·∫£ th·∫ª <a> trong ph·∫ßn t·ª≠ n√†y
                title_elem_a = elem.find("a")  # ƒê·ªïi t·ª´ class="te-stream-title-2" th√†nh t√¨m th·∫ª <a> b·∫•t k·ª≥
                link = None
                title = None

                if title_elem_a:
                    # T√¨m th·∫ª <b> b√™n trong <a> ƒë·ªÉ l·∫•y ti√™u ƒë·ªÅ
                    bold_elem = title_elem_a.find("b")
                    if bold_elem:
                        title = bold_elem.text.strip()
                        print(f"B√†i {i}: Ti√™u ƒë·ªÅ t·ª´ th·∫ª <b> trong <a>: {title}")
                    else:
                        title = title_elem_a.text.strip()
                        print(f"B√†i {i}: Ti√™u ƒë·ªÅ t·ª´ th·∫ª <a>: {title}")

                    raw_link = title_elem_a.get("href")
                    if raw_link:
                        link = normalize_url(raw_link)
                        print(f"B√†i {i}: Link: {link}")
                    else:
                        print(f"B√†i {i}: Kh√¥ng t√¨m th·∫•y href trong th·∫ª <a>")
                else:
                    # N·∫øu kh√¥ng t√¨m th·∫•y th·∫ª <a>, th·ª≠ t√¨m th·∫ª <b> tr·ª±c ti·∫øp
                    bold_elem = elem.find("b")
                    if bold_elem:
                        title = bold_elem.text.strip()
                        print(f"B√†i {i}: Ti√™u ƒë·ªÅ t·ª´ th·∫ª <b> tr·ª±c ti·∫øp: {title}")
                    else:
                        print(f"B√†i {i}: Kh√¥ng t√¨m th·∫•y th·∫ª <a> ho·∫∑c <b>")

                if not title or title in seen_titles:
                    print(f"B√†i {i}: Ti√™u ƒë·ªÅ r·ªóng ho·∫∑c ƒë√£ t·ªìn t·∫°i: {title}")
                    continue
                seen_titles.add(title)

                absolute_time = parse_relative_time(relative_time, reference_date=datetime.now())
                if absolute_time is None:
                    print(f"B√†i {i}: Th·ªùi gian kh√¥ng h·ª£p l·ªá: {relative_time}")
                    continue
                print(f"B√†i {i}: Th·ªùi gian tuy·ªát ƒë·ªëi: {absolute_time}, kho·∫£ng: {start_of_day} - {end_of_day}")

                if start_of_day <= absolute_time <= end_of_day:
                    articles.append({
                        "title": title,
                        "link": link,  # Cho ph√©p link l√† None
                        "time": absolute_time
                    })
                else:
                    print(f"B√†i {i}: Ngo√†i kho·∫£ng th·ªùi gian ng√†y {specific_date.strftime('%d/%m/%Y')}")

            if len(articles) >= max_articles:
                print(f"ƒê√£ ƒë·∫°t s·ªë l∆∞·ª£ng t·ªëi ƒëa {max_articles} b√†i vi·∫øt, d·ª´ng thu th·∫≠p.")
                break

        print(f"S·ªë l∆∞·ª£ng b√†i vi·∫øt h·ª£p l·ªá trong ng√†y {specific_date.strftime('%d/%m/%Y')}: {len(articles)}")

        articles = sorted(articles, key=lambda x: x["time"], reverse=True)[:max_articles]
        for article in articles:
            article["time"] = article["time"].strftime("%Y-%m-%d %H:%M:%S")

    except Exception as e:
        print(f"L·ªói khi thu th·∫≠p b√†i vi·∫øt: {e}")
    finally:
        driver.quit()

    return articles
# H√†m chu·∫©n h√≥a URL
def normalize_url(link):
    base_url = "https://tradingeconomics.com"
    if not link or not isinstance(link, str):
        return None
    if not link.startswith("http"):
        return urljoin(base_url, link)
    return link

# H√†m t√≥m t·∫Øt b√†i vi·∫øt v·ªõi b·ªô nh·ªõ ƒë·ªám
@lru_cache(maxsize=50)
def analyze_article(link):
    if not link or not isinstance(link, str):
        return "L·ªói: URL kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng t·ªìn t·∫°i."
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
        }
        response = requests.get(link, headers=headers, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, "html.parser")
        content = soup.find("h2", id="description")
        if content:
            content_text = content.get_text(separator="\n").strip()
            if len(content_text) > 100:
                summary = summarizer(content_text, max_length=130, min_length=30, do_sample=False)
                return summary[0]["summary_text"]
            else:
                return "N·ªôi dung b√†i vi·∫øt qu√° ng·∫Øn ƒë·ªÉ t√≥m t·∫Øt."
        else:
            return "Kh√¥ng t√¨m th·∫•y n·ªôi dung b√†i vi·∫øt."
    except Exception as e:
        return f"L·ªói khi ph√¢n t√≠ch b√†i vi·∫øt: {str(e)}"

# H√†m h·ªó tr·ª£ t√≥m t·∫Øt song song
def summarize_articles(articles):
    valid_articles = [article for article in articles if article.get("link")]  # L·ªçc c√°c b√†i c√≥ link h·ª£p l·ªá
    if not valid_articles:
        return {}
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_article = {executor.submit(analyze_article, article["link"]): article for article in valid_articles}
        summaries = {}
        for future in as_completed(future_to_article):
            article = future_to_article[future]
            try:
                summary = future.result()
                summaries[article["title"]] = summary
            except Exception as e:
                summaries[article["title"]] = f"L·ªói khi t√≥m t·∫Øt: {str(e)}"
    return summaries

# L·ªánh /start
async def start_command(update: Update, context: CallbackContext):
    welcome_message = (
        "Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi bot Trading Economics!\n"
        "Bot n√†y cung c·∫•p tin t·ª©c v√† d·ªØ li·ªáu th·ªã tr∆∞·ªùng t·ª´ Trading Economics.\n\n"
        "C√°c l·ªánh kh·∫£ d·ª•ng:\n"
        "- /start: Hi·ªÉn th·ªã tin nh·∫Øn ch√†o m·ª´ng\n"
        "- /help: Xem h∆∞·ªõng d·∫´n\n"
        "- /news [dd/mm/yyyy]: L·∫•y 10 b√†i tin t·ª©c m·ªõi nh·∫•t trong ng√†y ch·ªâ ƒë·ªãnh (m·∫∑c ƒë·ªãnh l√† h√¥m nay)\n"
        "- /stocks: L·∫•y d·ªØ li·ªáu ch·ªâ s·ªë c·ªï phi·∫øu\n"
        "- /commodities: L·∫•y d·ªØ li·ªáu gi√° h√†ng h√≥a\n"
        "- /financials: L·∫•y d·ªØ li·ªáu t√†i ch√≠nh\n"
    )
    await context.bot.send_message(chat_id=update.effective_chat.id, text=welcome_message)

# L·ªánh /help
async def help_command(update: Update, context: CallbackContext):
    help_message = (
        "H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng bot:\n\n"
        "C√°c l·ªánh kh·∫£ d·ª•ng:\n"
        "- /start: Hi·ªÉn th·ªã tin nh·∫Øn ch√†o m·ª´ng\n"
        "- /help: Xem h∆∞·ªõng d·∫´n n√†y\n"
        "- /news [dd/mm/yyyy]: L·∫•y 10 b√†i tin t·ª©c m·ªõi nh·∫•t trong ng√†y ch·ªâ ƒë·ªãnh (m·∫∑c ƒë·ªãnh l√† h√¥m nay). V√≠ d·ª•: /news 03/09/2025\n"
        "- /stocks: L·∫•y d·ªØ li·ªáu ch·ªâ s·ªë c·ªï phi·∫øu th·∫ø gi·ªõi\n"
        "- /commodities: L·∫•y d·ªØ li·ªáu gi√° c·∫£ h√†ng h√≥a\n"
        "- /financials: L·∫•y d·ªØ li·ªáu t·ª∑ gi√° ti·ªÅn t·ªá\n\n"
        "Bot c≈©ng g·ª≠i b√°o c√°o th·ªã tr∆∞·ªùng t·ª± ƒë·ªông h√†ng ng√†y."
    )
    await context.bot.send_message(chat_id=update.effective_chat.id, text=help_message)

# L·ªánh /news
async def news_command(update: Update, context: CallbackContext):
    if context.args:
        try:
            specific_date = datetime.strptime(context.args[0], "%d/%m/%Y")
        except ValueError:
            await context.bot.send_message(chat_id=update.effective_chat.id, text="‚ùå ƒê·ªãnh d·∫°ng ng√†y kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p theo ƒë·ªãnh d·∫°ng dd/mm/yyyy, v√≠ d·ª•: 03/09/2025")
            return
    else:
        specific_date = datetime.now()

    date_str = specific_date.strftime("%d/%m/%Y")
    await context.bot.send_message(chat_id=update.effective_chat.id, text=f"‚è≥ ƒêang thu th·∫≠p tin t·ª©c trong ng√†y {date_str}, vui l√≤ng ƒë·ª£i...")
    articles = fetch_articles(max_articles=10, specific_date=specific_date)
    
    if not articles:
        await context.bot.send_message(chat_id=update.effective_chat.id, text=f"‚ùå Kh√¥ng t√¨m th·∫•y b√†i vi·∫øt n√†o trong ng√†y {date_str} ho·∫∑c c√≥ l·ªói khi t·∫£i. Vui l√≤ng ki·ªÉm tra log ƒë·ªÉ bi·∫øt chi ti·∫øt!")
        return
    elif len(articles) < 10:
        await context.bot.send_message(chat_id=update.effective_chat.id, text=f"‚ö†Ô∏è Ch·ªâ t√¨m th·∫•y {len(articles)} b√†i vi·∫øt trong ng√†y {date_str} thay v√¨ 10. Ki·ªÉm tra log ƒë·ªÉ bi·∫øt chi ti·∫øt.")

    await context.bot.send_message(chat_id=update.effective_chat.id, text="üìù ƒêang t√≥m t·∫Øt b√†i vi·∫øt...")
    summaries = summarize_articles(articles)

    message = f"üìù Tin t·ª©c m·ªõi nh·∫•t trong ng√†y {date_str}:\n\n"
    for article in articles:
        title = article["title"]
        summary = summaries.get(title, "Kh√¥ng th·ªÉ t√≥m t·∫Øt b√†i vi·∫øt n√†y.")
        link = article["link"]
        time = article["time"]
        message += f"<b>{title}</b>\n<i>{time}</i>\n{summary}\n<a href='{link}'>ƒê·ªçc th√™m</a>\n\n" if link else f"<b>{title}</b>\n<i>{time}</i>\n{summary}\n"

    await context.bot.send_message(chat_id=update.effective_chat.id, text=message, parse_mode='HTML')

# L·ªánh /stocks
async def stocks_command(update: Update, context: CallbackContext):
    await context.bot.send_message(chat_id=update.effective_chat.id, text="ƒêang t·∫£i d·ªØ li·ªáu c·ªï phi·∫øu...")
    table, chart = fetch_stocks_data()
    if not table.startswith("Kh√¥ng th·ªÉ"):
        await context.bot.send_message(chat_id=update.effective_chat.id, text=table, parse_mode='HTML')
        if chart and os.path.exists(chart):
            with open(chart, 'rb') as f:
                await context.bot.send_photo(chat_id=update.effective_chat.id, photo=f)
            os.remove(chart)
    else:
        await context.bot.send_message(chat_id=update.effective_chat.id, text=table)

# L·ªánh /commodities
async def commodities_command(update: Update, context: CallbackContext):
    await context.bot.send_message(chat_id=update.effective_chat.id, text="ƒêang t·∫£i d·ªØ li·ªáu h√†ng h√≥a...")
    table, chart = fetch_commodities_data()
    if not table.startswith("Kh√¥ng th·ªÉ"):
        await context.bot.send_message(chat_id=update.effective_chat.id, text=table, parse_mode='HTML')
        if chart and os.path.exists(chart):
            with open(chart, 'rb') as f:
                await context.bot.send_photo(chat_id=update.effective_chat.id, photo=f)
            os.remove(chart)
    else:
        await context.bot.send_message(chat_id=update.effective_chat.id, text=table)

# L·ªánh /financials
async def financials_command(update: Update, context: CallbackContext):
    await context.bot.send_message(chat_id=update.effective_chat.id, text="ƒêang t·∫£i d·ªØ li·ªáu t√†i ch√≠nh...")
    table, chart = fetch_financials_data()
    if not table.startswith("Kh√¥ng th·ªÉ"):
        await context.bot.send_message(chat_id=update.effective_chat.id, text=table, parse_mode='HTML')
        if chart and os.path.exists(chart):
            with open(chart, 'rb') as f:
                await context.bot.send_photo(chat_id=update.effective_chat.id, photo=f)
            os.remove(chart)
    else:
        await context.bot.send_message(chat_id=update.effective_chat.id, text=table)

# H√†m g·ª≠i b√°o c√°o t·ª± ƒë·ªông h√†ng ng√†y
async def send_daily_report(context: CallbackContext):
    for fetch_func, name in [
        (fetch_stocks_data, "c·ªï phi·∫øu"),
        (fetch_commodities_data, "h√†ng h√≥a"),
        (fetch_financials_data, "t√†i ch√≠nh")
    ]:
        await context.bot.send_message(chat_id=CHAT_ID, text=f"ƒêang t·∫£i d·ªØ li·ªáu {name}...")
        table, chart = fetch_func()
        if not table.startswith("Kh√¥ng th·ªÉ"):
            await context.bot.send_message(chat_id=CHAT_ID, text=table, parse_mode='HTML')
            if chart and os.path.exists(chart):
                with open(chart, 'rb') as f:
                    await context.bot.send_photo(chat_id=CHAT_ID, photo=f)
                os.remove(chart)
        else:
            await context.bot.send_message(chat_id=CHAT_ID, text=table)
        time.sleep(1)

# H√†m ch√≠nh
def main():
    application = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("news", news_command))
    application.add_handler(CommandHandler("stocks", stocks_command))
    application.add_handler(CommandHandler("commodities", commodities_command))
    application.add_handler(CommandHandler("financials", financials_command))
    application.job_queue.run_daily(send_daily_report, time=dt_time(hour=8, minute=0))
    print("ü§ñ Bot ƒëang ch·∫°y...")
    application.run_polling()

if __name__ == "__main__":
    main()